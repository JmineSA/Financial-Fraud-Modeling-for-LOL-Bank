{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93e1da70-0fbc-4cf0-9bdb-856bcb59946b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üöÄ 2025 Intelligent Fraud Detection in Banking Transactions üè¶  \n",
    "\n",
    "## üìå Problem  \n",
    "- Increasing **online & digital banking** ‚Üí more **fraudulent activities** (‚ö†Ô∏è identity theft, unauthorized access, suspicious patterns).  \n",
    "- Traditional methods = **reactive & outdated**, struggle with evolving fraud tactics.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Available  \n",
    "- üë§ **Customer Info**: ID, name, gender, age, location, account type.  \n",
    "- üí≥ **Transaction Info**: ID, date, time, amount, type, balance, currency.  \n",
    "- üõçÔ∏è **Merchant Info**: ID, category, location.  \n",
    "- üíª **Device/Network Info**: device type, location, transaction device.  \n",
    "- üö© **Fraud Label**: `Is_Fraud` (0 = genuine, 1 = fraud).  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives  \n",
    "- üîé Detect **fraudulent transactions in real time**.  \n",
    "- ‚ö° Minimize **false positives** (don‚Äôt block genuine transactions).  \n",
    "- üß† Adapt to **new fraud strategies** through ML.  \n",
    "- ü§ù Enhance **customer trust & security**.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## üöÄ Expected Outcomes  \n",
    "- üí∞ Reduce **financial losses**.  \n",
    "- üì¢ Provide **real-time alerts** for fast action.  \n",
    "- üîê Strengthen **security & compliance**.  \n",
    "- üôå Increase **customer confidence**.  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Challenges  \n",
    "- ‚öñÔ∏è **Imbalanced dataset** (fraud = small % of all transactions).  \n",
    "- üîè **Privacy & security concerns** with sensitive data.  \n",
    "- üñ•Ô∏è **Real-time processing power** needed for smooth user experience.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bab013a-567d-44ed-a63a-d070732edc64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136a37f8-2393-48cf-8b82-ac9155a28a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# PANDAS & SEABORN CONFIGURATION\n",
    "# ======================================\n",
    "\n",
    "# ----- PANDAS DISPLAY SETTINGS -----\n",
    "# Display all columns and rows without truncation\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', 100)  # Limit rows to avoid excessive output\n",
    "pd.set_option('display.width', 1000)    # Adjust display width for better readability\n",
    "pd.set_option('display.colheader_justify', 'center')  # Center-align headers\n",
    "\n",
    "# Floating-point precision (2 decimal places)\n",
    "pd.options.display.float_format = '{:,.2f}'.format  # Adds thousand separators\n",
    "\n",
    "# Improve performance with larger datasets\n",
    "pd.set_option('compute.use_numexpr', True)  # Faster numerical operations\n",
    "pd.set_option('mode.chained_assignment', 'warn')  # Warn on chained assignments\n",
    "\n",
    "# ----- SEABORN & MATPLOTLIB STYLING -----\n",
    "# Set a modern and clean style\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\",  # Background grid for better readability\n",
    "    context=\"notebook\",  # Optimize for notebook display\n",
    "    palette=\"deep\",      # Aesthetic color palette\n",
    "    font=\"sans-serif\",   # Clean font\n",
    "    font_scale=1.1,      # Slightly larger font size\n",
    "    rc={\n",
    "        'figure.figsize': (10, 6),  # Default figure size\n",
    "        'axes.titlesize': 16,       # Title font size\n",
    "        'axes.labelsize': 14,        # Axis label size\n",
    "        'xtick.labelsize': 12,      # X-tick label size\n",
    "        'ytick.labelsize': 12,       # Y-tick label size\n",
    "        'grid.alpha': 0.3,          # Grid transparency\n",
    "    }\n",
    ")\n",
    "\n",
    "# Improve matplotlib defaults\n",
    "plt.rcParams['figure.dpi'] = 100      # Higher resolution for figures\n",
    "plt.rcParams['savefig.dpi'] = 300     # High DPI for saved figures\n",
    "plt.rcParams['lines.linewidth'] = 2   # Thicker plot lines\n",
    "plt.rcParams['axes.edgecolor'] = '0.15'  # Softer axis edge color\n",
    "\n",
    "# Disable scientific notation for small numbers\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.set_printoptions(suppress=True)   # Suppress scientific notation in NumPy\n",
    "\n",
    "# Suppress unnecessary warnings (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)  # Ignore FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)  # Ignore PerformanceWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ba0e1ad-ab82-445a-a6a4-ae2f577a894f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset with error handling\n",
    "try:\n",
    "    \n",
    "    # Replace this with the correct path to your dataset file\n",
    "    df = pd.read_csv(r'G:\\Study\\DATA SCINCE\\PROJECTS\\POTFOLIO\\Financial Fraud Modeling for LOL Bank\\Data\\Bank_Transaction_Fraud_Detection.csv')\n",
    "    print(\" Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape} (Rows: {df.shape[0]}, Columns: {df.shape[1]})\")\n",
    "    \n",
    "    # Display first 3 rows \n",
    "    display(df.head(3))\n",
    "    \n",
    "    # Basic info\n",
    "    print(\"\\n Data Overview:\")\n",
    "    display(df.info(verbose=True, show_counts=True))  # Shows non-null counts & dtypes\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\n Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "    # Missing values summary\n",
    "    print(\"\\n Missing Values:\")\n",
    "    missing = df.isna().sum().to_frame(name=\"Missing Values\")\n",
    "    missing[\"% Missing\"] = (missing[\"Missing Values\"] / len(df)) * 100\n",
    "    display(missing.sort_values(\"% Missing\", ascending=False))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\" Error: File not found. Check the file path!\")\n",
    "except Exception as e:\n",
    "    print(f\" Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7012c4d1-ef48-4f04-aa62-cea194e4be0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üïí Date & Time Formatting\n",
    "- The `Transaction_Date` and `Transaction_Time` columns need to be **converted to proper datetime format** for accurate analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "816eac0d-3389-4932-85c6-3af18d5a5e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DATA CLEANING & PRE-PROCESSING\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88efd89d-2b88-466b-855f-5300e281f659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handling Transaction_Date\n",
    "df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'], format='%d-%m-%Y')\n",
    "df['Day'] = df['Transaction_Date'].dt.day\n",
    "df['Month'] = df['Transaction_Date'].dt.month\n",
    "df['Weekday'] = df['Transaction_Date'].dt.weekday\n",
    "df['Is_Weekend'] = df['Transaction_Date'].dt.weekday >= 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf321f9e-4117-4adb-ad33-75944095a0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handling Transaction_time\n",
    "\n",
    "df['Transaction_Time'] = pd.to_datetime(df['Transaction_Time'], format='%H:%M:%S')\n",
    "df['Hour'] = df['Transaction_Time'].dt.hour\n",
    "df['Minutes'] = df['Transaction_Time'].dt.minute\n",
    "df['Seconds'] = df['Transaction_Time'].dt.second\n",
    "\n",
    "def time_bucket(h):\n",
    "    if 5 <= h <= 11: return 'Morning'\n",
    "    elif 12 <= h <= 17: return 'Afternoon'\n",
    "    elif 18 <= h <= 22: return 'Evening'\n",
    "    else: return 'Night'\n",
    "\n",
    "df['Time_Bucket'] = df['Hour'].apply(time_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd22390b-ee43-4c06-9bb6-972567adc575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìä Exploratory Data Analysis (EDA)\n",
    "\n",
    "The goal of EDA is to understand the dataset, uncover patterns, spot anomalies, and generate hypotheses for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "324e5df4-5e08-459b-b8d1-bbc258760417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def dataset_summary(df):\n",
    "    \"\"\"\n",
    "    Display  summary statistics for numerical and categorical columns\n",
    "    in a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas.DataFrame\n",
    "        The dataset to analyze.\n",
    "    \"\"\"\n",
    "    # Numerical columns summary\n",
    "    print(\" Numerical Columns Summary:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    # Categorical columns summary\n",
    "    print(\"\\n Categorical Columns Summary:\")\n",
    "    display(df.describe(include=['object', 'category']))\n",
    "dataset_summary(df)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de78eef6-fc63-4998-a26b-2c330d8306c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìä Part 1: The Macro View - Understanding the Landscape of Fraud  \n",
    "\n",
    "## üîé 1.1 Target Variable Analysis: The Scale of the Problem  \n",
    "\n",
    "The first step in exploring fraud detection is to examine the **target variable** üéØ `Is_Fraud`.  \n",
    "This variable indicates whether a transaction is **fraudulent (`1`) üö®** or **legitimate (`0`) ‚úÖ**.  \n",
    "\n",
    "Understanding its distribution helps us see the **scale of the fraud problem üìâ** and whether we are dealing with a **class imbalance ‚öñÔ∏è**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7734fc35-1129-4b1d-82fb-9e559cae757a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution of fraudulent vs legitimate transactions\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(data=df, x='Is_Fraud', palette=['#2ecc71', \"#e62611\"])\n",
    "\n",
    "\n",
    "# Add count values inside of bars\n",
    "total = len(df)\n",
    "for i, p in enumerate(ax.patches):\n",
    "    percentage = f'{(p.get_height()/total)*100:.0f}%'\n",
    "    ax.text(p.get_x() + p.get_width()/2., p.get_height()/2,\n",
    "            percentage, ha='center', va='center', fontsize=14, \n",
    "            fontweight='bold', color='white')\n",
    "    \n",
    "\n",
    "#Plot title and labels\n",
    "plt.title('Fraud vs Legitimate Transactions Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Transaction Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks([0, 1], ['Legitimate (0)', 'Fraudulent (1)'])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "\n",
    "# Add some context text\n",
    "fraud_count = df['Is_Fraud'].sum()\n",
    "fraud_percentage = (fraud_count / total) * 100\n",
    "plt.figtext(0.5, 0.01, f'Dataset is highly imbalanced: Only {fraud_percentage:.0f}% fraudulent transactions', \n",
    "            ha='center', fontsize=10, style='italic', bbox={'facecolor': 'lightyellow', 'alpha': 0.5})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "312d15a2-ccaa-4e6c-a97d-ea689b53c012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate fraud rate\n",
    "fraud_rate = df['Is_Fraud'].mean() * 100\n",
    "legit_count, fraud_count = df['Is_Fraud'].value_counts()\n",
    "print(f\"Legitimate Transactions: {legit_count} ({100-fraud_rate:.2f}%)\")\n",
    "print(f\"Fraudulent Transactions: {fraud_count} ({fraud_rate:.2f}%)\")\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "colors = ['#66b3ff',\"#fa1b1b\"]\n",
    "\n",
    "# Count plot\n",
    "ax1.pie([legit_count, fraud_count], labels=['Legitimate', 'Fraud'], colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Overall Transaction Distribution', fontweight='bold')\n",
    "\n",
    "# Fraud Rate bar\n",
    "ax2.bar(['Fraud Rate'], [fraud_rate], color='#ff9999')\n",
    "ax2.axhline(y=fraud_rate, color='r', linestyle='--', alpha=0.5, label=f'Global Average: {fraud_rate:.2f}%')\n",
    "ax2.set_ylabel('Percentage (%)')\n",
    "ax2.set_title('Global Fraud Rate')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e7d8265-9ab7-487e-8608-d099f0a78e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìå Insights  \n",
    "\n",
    "The dataset exhibits a **classic high-class imbalance** üìâ, with only **5% of transactions being fraudulent üö®**.  \n",
    "\n",
    "While this fraction may appear small, it represents a **significant financial risk üí∏**.  \n",
    "\n",
    "The primary business challenge is to build a model that can identify this **\"needle in a haystack\" ü™°** without overwhelming analysts with **false positives ‚ùå‚úÖ**.  \n",
    "\n",
    "üëâ The cost of **missing a fraudulent transaction (false negative ‚ö†Ô∏è)** is much higher than **incorrectly flagging a legitimate one (false positive ü§î)**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e17bedb-3297-44ce-89be-075623520408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 2: The \"When\" - Temporal Patterns of Fraud  \n",
    "\n",
    "## 2.1 ‚è∞  \n",
    "\n",
    "### üìå Insights  \n",
    "Fraudulent transactions are not uniformly distributed across the day.  \n",
    "Instead, they exhibit **temporal spikes** that align with times when oversight is lower üïµÔ∏è‚Äç‚ôÇÔ∏è‚¨áÔ∏è.  \n",
    "\n",
    "- **Higher fraud rates** are often observed during **late-night to early-morning hours üåô**.  \n",
    "- Fraudsters exploit periods of **reduced monitoring and staff presence üí§**.  \n",
    "- This temporal clustering provides a window for **real-time fraud detection systems ‚è±Ô∏è** to be more vigilant during ‚Äúrisky hours.‚Äù  \n",
    "\n",
    "üëâ Understanding the **\"when\"** allows businesses to **proactively allocate resources** and **tighten transaction monitoring** during high-risk windows.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d88687b-baf5-4869-909f-5a59ca29d471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract hour from datetime\n",
    "df['Hour'] = df['Transaction_Time'].dt.hour\n",
    "hourly_fraud_rate = df.groupby('Hour')['Is_Fraud'].mean() * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(hourly_fraud_rate.index, hourly_fraud_rate.values, color='salmon')\n",
    "plt.axhline(y=fraud_rate, color='r', linestyle='--', label=f'Global Avg Fraud Rate ({fraud_rate:.2f}%)')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Fraud Rate (%)')\n",
    "plt.title('Fraud Rate by Hour of Day: Identifying High-Risk Windows', fontweight='bold', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Annotate the peak hours\n",
    "peak_hours = hourly_fraud_rate.nlargest(3)\n",
    "for hour, rate in peak_hours.items():\n",
    "    plt.annotate(f'{rate:.2f}%', xy=(hour, rate), xytext=(hour, rate+0.05),\n",
    "                 ha='center', va='bottom', fontweight='bold', color='darkred')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.4)\n",
    "plt.xticks(range(0,24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "286139dd-a911-4084-90ed-49fbbaa36a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Perform analysis on the original df for exploration ---\n",
    "print(\"\\nEngineering time-based features for analysis...\")\n",
    "\n",
    "\n",
    "\n",
    "# Create Transaction_DateTime - handle both date and time properly\n",
    "if 'Transaction_Time' in df.columns:\n",
    "    df['Transaction_DateTime'] = pd.to_datetime(\n",
    "        df['Transaction_Date'].astype(str) + ' ' + df['Transaction_Time'].astype(str),\n",
    "        errors='coerce'\n",
    "    )\n",
    "else:\n",
    "    df['Transaction_DateTime'] = pd.to_datetime(df['Transaction_Date'], errors='coerce')\n",
    "\n",
    "# Remove any rows with invalid datetime\n",
    "df = df.dropna(subset=['Transaction_DateTime'])\n",
    "\n",
    "# Extract hour from datetime\n",
    "df['Hour'] = df['Transaction_DateTime'].dt.hour\n",
    "\n",
    "# Create time buckets\n",
    "def get_time_bucket(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning (5-11)'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon (12-16)'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening (17-20)'\n",
    "    else:\n",
    "        return 'Night (21-4)'\n",
    "\n",
    "df['Time_Bucket'] = df['Hour'].apply(get_time_bucket)\n",
    "\n",
    "# Extract weekday and weekend indicator\n",
    "df[\"Weekday\"] = df[\"Transaction_DateTime\"].dt.dayofweek\n",
    "df[\"Is_Weekend\"] = df[\"Weekday\"].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Calculate fraud rates for different groupings\n",
    "fraud_rate_by_weekday = df.groupby(\"Weekday\")[\"Is_Fraud\"].mean()\n",
    "fraud_rate_weekend = df.groupby(\"Is_Weekend\")[\"Is_Fraud\"].mean()\n",
    "fraud_rate_by_time_bucket = df.groupby(\"Time_Bucket\")[\"Is_Fraud\"].mean()\n",
    "\n",
    "# Create a figure with three subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# --- Plot 1: Detailed View by Weekday ---\n",
    "weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "bars1 = ax1.bar(fraud_rate_by_weekday.index, fraud_rate_by_weekday.values, \n",
    "               color='skyblue', alpha=0.7, edgecolor='black', label='Daily Rate')\n",
    "\n",
    "# Add line plot on top of the bars\n",
    "ax1.plot(fraud_rate_by_weekday.index, fraud_rate_by_weekday.values, \n",
    "        marker='o', linestyle='-', color='red', linewidth=3, \n",
    "        markersize=8, markerfacecolor='white', markeredgecolor='red', \n",
    "        markeredgewidth=2, label='Trend Line')\n",
    "\n",
    "# Add average line\n",
    "average_fraud = fraud_rate_by_weekday.mean()\n",
    "ax1.axhline(y=average_fraud, color='green', linestyle='--', linewidth=2, \n",
    "           alpha=0.8, label=f'Weekly Avg: {average_fraud:.4f}')\n",
    "\n",
    "ax1.set_xlabel(\"Day of the Week\", fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel(\"Fraud Rate\", fontsize=12, fontweight='bold')\n",
    "ax1.set_title(\" Fraud Rate by Day of the Week\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(7))\n",
    "ax1.set_xticklabels(weekday_names, fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Add value annotations to weekday bars\n",
    "for i, (bar, v) in enumerate(zip(bars1, fraud_rate_by_weekday.values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "             f'{v:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "# --- Plot 2: Weekend vs. Weekday Comparison ---\n",
    "weekend_labels = ['Weekday\\n(Mon-Fri)', 'Weekend\\n(Sat-Sun)']\n",
    "bars2 = ax2.bar(weekend_labels, fraud_rate_weekend.values, \n",
    "               color=['lightblue', 'lightcoral'], alpha=0.8, edgecolor='black', width=0.6)\n",
    "ax2.set_xlabel(\"Time Period\", fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel(\"Fraud Rate\", fontsize=12, fontweight='bold')\n",
    "ax2.set_title(\" Average Fraud Rate: Weekday vs. Weekend\", fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels to weekend/weekday bars\n",
    "for i, (bar, v) in enumerate(zip(bars2, fraud_rate_weekend.values)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "             f'{v:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# --- Plot 3: Time Bucket Analysis ---\n",
    "time_bucket_order = ['Morning (5-11)', 'Afternoon (12-16)', 'Evening (17-20)', 'Night (21-4)']\n",
    "fraud_rate_ordered = fraud_rate_by_time_bucket.reindex(time_bucket_order)\n",
    "\n",
    "bars3 = ax3.bar(range(len(fraud_rate_ordered)), fraud_rate_ordered.values, \n",
    "               color=['lightyellow', 'lightgreen', 'orange', 'lightcoral'], \n",
    "               alpha=0.8, edgecolor='black', width=0.7)\n",
    "ax3.set_xlabel(\"Time of Day\", fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel(\"Fraud Rate\", fontsize=12, fontweight='bold')\n",
    "ax3.set_title(\" Fraud Rate by Time of Day\", fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(range(len(time_bucket_order)))\n",
    "ax3.set_xticklabels(time_bucket_order, rotation=45, ha='right', fontsize=11)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels to time bucket bars\n",
    "for i, (bar, v) in enumerate(zip(bars3, fraud_rate_ordered.values)):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "             f'{v:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Set consistent y-axis limits across all plots for better comparison\n",
    "all_rates = list(fraud_rate_by_weekday.values) + list(fraud_rate_weekend.values) + list(fraud_rate_ordered.values)\n",
    "y_max = max(all_rates) * 1.15  # Add 15% padding\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_ylim(0, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics with proper alignment\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FRAUD RATE SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÖ BY DAY OF WEEK:\")\n",
    "print(\"-\" * 30)\n",
    "for day, rate in zip(weekday_names, fraud_rate_by_weekday.values):\n",
    "    print(f\"{day}: {rate:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Weekly Average: {fraud_rate_by_weekday.mean():.4f}\")\n",
    "\n",
    "print(\"\\nüèñÔ∏è WEEKDAY vs WEEKEND:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Weekday (Mon-Fri): {fraud_rate_weekend[0]:.4f}\")\n",
    "print(f\"Weekend (Sat-Sun): {fraud_rate_weekend[1]:.4f}\")\n",
    "difference = fraud_rate_weekend[1] - fraud_rate_weekend[0]\n",
    "print(f\"Difference: {difference:+.4f} ({difference/fraud_rate_weekend[0]*100:+.1f}%)\")\n",
    "\n",
    "print(\"\\nüïí BY TIME OF DAY:\")\n",
    "print(\"-\" * 30)\n",
    "for bucket, rate in fraud_rate_ordered.items():\n",
    "    print(f\"{bucket}: {rate:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Time-of-Day Average: {fraud_rate_ordered.mean():.4f}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1512f5-bdad-4a46-b25b-173a0f91747d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚è∞ Temporal Fraud Summary  \n",
    "\n",
    "Fraudulent transactions exhibit **clear temporal patterns**:  \n",
    "\n",
    "- **Peak Hours:** 2 AM ‚Äì 5 AM, with fraud rates (~5.3%) above the global average (5.04%) üö®  \n",
    "- **Day of Week:** Mondays and Wednesdays show slightly higher fraud rates (~5.17%) üìÖ  \n",
    "- **Weekday vs Weekend:** Weekdays see marginally higher fraud (5.09%) than weekends (4.91%) üèñÔ∏è  \n",
    "- **Time of Day:** Night (21-4) is riskiest at 5.15%, while afternoon (12-16) is least risky at 4.93% üåô  \n",
    "\n",
    "### üí° Insight:\n",
    "Temporal signals are **strong predictors** of fraud, making **time-based monitoring** and **risk scoring** effective strategies for early detection.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "073e36bf-cf3b-4fb4-b470-4c70643b7e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Describe amounts for fraud vs non-fraud\n",
    "amount_summary = df.groupby('Is_Fraud')['Transaction_Amount'].describe()\n",
    "print(amount_summary)\n",
    "\n",
    "# Plot with log scale due to extreme outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Is_Fraud', y='Transaction_Amount', data=df, showfliers=False) # Remove outliers for readability\n",
    "\n",
    "plt.title('Distribution of Transaction Amount ( Outliers Removed for Clarity)', fontweight='bold')\n",
    "plt.ylabel('Transaction Amount (Log Scale)')\n",
    "plt.xlabel('Is Fraud?')\n",
    "plt.xticks([0,1], ['Legitimate', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "846ddaa9-4bf8-4cce-a841-d5708de7f94f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 4: The \"How\" - Channel and Method Analysis  \n",
    "\n",
    "## 4.1 üí≥ Transaction Type: The Digital Frontline  \n",
    "\n",
    "### üîé Overview  \n",
    "Different types of transactions (e.g., **Withdrawal, Deposit, Transfer**) present **varying levels of fraud risk**.  \n",
    "Analyzing the distribution of fraud across transaction types helps identify **vulnerable channels** and informs **risk mitigation strategies**.  \n",
    "\n",
    "### üìä Why It Matters  \n",
    "- Fraudsters often exploit **high-volume or less-monitored transaction types üö®**.  \n",
    "- Certain transaction types may have **higher fraud ratios üí∏** even if their volume is low.  \n",
    "- Insights from transaction type analysis guide **real-time monitoring** and **security measures** for high-risk operations.  \n",
    "\n",
    "### üõ†Ô∏è Steps for Analysis  \n",
    "1. Calculate **fraud count and fraud rate** per transaction type.  \n",
    "2. Visualize using **bar plots or horizontal bar charts** for clarity.  \n",
    "3. Highlight **high-risk transaction types** for further investigation.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae9852ae-cf13-4826-a80d-05920b215dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate fraud rate by merchant category\n",
    "category_fraud_rate = (df.groupby('Merchant_Category')['Is_Fraud']\n",
    "                       .agg(['mean', 'count'])\n",
    "                       .round(4) * 100)\n",
    "category_fraud_rate.columns = ['Fraud_Rate_Pct', 'Total_Transactions']\n",
    "category_fraud_rate = category_fraud_rate[category_fraud_rate['Total_Transactions'] > 50] # Filter out rare categories\n",
    "top_10_risky = category_fraud_rate.nlargest(10, 'Fraud_Rate_Pct')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(top_10_risky.index, top_10_risky['Fraud_Rate_Pct'], color='indianred')\n",
    "plt.axvline(x=fraud_rate, color='r', linestyle='--', label=f'Global Avg ({fraud_rate:.2f}%)')\n",
    "plt.xlabel('Fraud Rate (%)')\n",
    "plt.title('Top 10 Riskiest Merchant Categories by Fraud Rate', fontweight='bold', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width+0.05, bar.get_y() + bar.get_height()/2, f'{width:.2f}%', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f000f13-8684-47de-8c95-8c92bfe212d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fraud rate by transaction type\n",
    "type_fraud_rate = (df.groupby('Transaction_Type')['Is_Fraud'].mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=type_fraud_rate.values, y=type_fraud_rate.index, palette='Reds_r')\n",
    "plt.axvline(x=fraud_rate, color='r', linestyle='--', label=f'Global Avg ({fraud_rate:.2f}%)')\n",
    "plt.xlabel('Fraud Rate (%)')\n",
    "plt.title('Fraud Rate by Transaction Channel', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37a86d54-d269-4231-b582-61e6df5e0c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate top 10 devices by fraud rate\n",
    "top_10_Transaction_Device = df.groupby('Transaction_Device')['Is_Fraud'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(f\"üì± Top 10 Transaction Devices by Fraud Rate:\")\n",
    "print(top_10_Transaction_Device.to_string())\n",
    "\n",
    "\n",
    "# Vertical bar plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "bars = plt.bar(range(len(top_10_Transaction_Device)), top_10_Transaction_Device.values,\n",
    "               color='lightblue', alpha=0.8, edgecolor='navy')\n",
    "\n",
    "plt.xlabel('Transaction Device', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Fraud Rate', fontsize=12, fontweight='bold')\n",
    "plt.title(' Top 10 Transaction Devices by Fraud Rate', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(top_10_Transaction_Device)), top_10_Transaction_Device.index, \n",
    "           rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(bars, top_10_Transaction_Device.values)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 0.001,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "becaea1c-ac96-4ce2-b5a0-21edd5d41e2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_5_types = df.groupby('Device_Type')['Is_Fraud'].mean().sort_values(ascending=False).head(5)\n",
    "print(f\"üì± Top 5 Device Types by Fraud Rate:\")\n",
    "print(top_5_types.to_string())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(top_5_types.index, top_5_types.values, \n",
    "               color='lightgreen', alpha=0.8, edgecolor='darkgreen')\n",
    "plt.xlabel('Device Type', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Fraud Rate', fontsize=12, fontweight='bold')\n",
    "plt.title(' Top 5 Device Types by Fraud Rate', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 0.001,\n",
    "             f'{height:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c9b3662-9664-4762-9627-dba935a67e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üí∏ Transaction Channel Fraud Insights  \n",
    "\n",
    "The **\"Transfer\" channel** is overwhelmingly the preferred method for fraud, accounting for **over 5.04% of all fraudulent transactions üö®**.  \n",
    "This aligns with merchant category findings and highlights the **anonymity and speed offered by digital transactions ‚ö°**.  \n",
    "\n",
    "The **\"Credit\" transactions üí≥** are the second riskiest, likely involving **cloned or compromised cards**.  \n",
    "\n",
    "In contrast, **\"In-Store\" or \"Bill Payment\" transactions üè™** have the **lowest fraud rate**, as they require **physical card possession** and often a **PIN üîí**.  \n",
    "\n",
    "Transaction_Device Debit/Credit Card  and Virtual Card has the highest rates with the use of desktop\n",
    "\n",
    "\n",
    "### üí° Insight:\n",
    "Understanding which channels are most targeted can help **prioritize monitoring and security measures** for high-risk transaction types.  ## üí∏ Transaction Channel Fraud Insights  \n",
    "\n",
    "The **\"Transfer\" channel** is overwhelmingly the preferred method for fraud, accounting for **over 5.04% of all fraudulent transactions üö®**.  \n",
    "This aligns with merchant category findings and highlights the **anonymity and speed offered by digital transactions ‚ö°**.  \n",
    "\n",
    "The **\"Credit\" transactions üí≥** are the second riskiest, likely involving **cloned or compromised cards**.  \n",
    "\n",
    "In contrast, **\"In-Store\" or \"Bill Payment\" transactions üè™** have the **lowest fraud rate**, as they require **physical card possession** and often a **PIN üîí**.  \n",
    "\n",
    "Additionally, the **Transaction_Device types** with the highest fraud rates are:  \n",
    "- **Debit/Credit Cards üí≥**  \n",
    "- **Virtual Cards üíª**  \n",
    "and fraud is more prevalent when these are used via **desktop devices üñ•Ô∏è**.  \n",
    "\n",
    "### üí° Insight:\n",
    "Understanding which channels and devices are most targeted helps **prioritize monitoring and security measures** for high-risk transaction types, improving detection and prevention efforts.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "438ac71f-01fa-40b5-9ae7-eb52999fb528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create age bins\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 25, 35, 45, 55, 65, 100],\n",
    "                         labels=['18-25', '26-35', '36-45', '46-55', '56-65', '66+'])\n",
    "\n",
    "# Calculate fraud rates\n",
    "age_fraud_rate = (df.groupby('Age_Group')['Is_Fraud'].mean() * 100)\n",
    "global_avg_fraud_rate = df['Is_Fraud'].mean() * 100\n",
    "\n",
    "# Calculate transaction counts per age group\n",
    "age_group_counts = df['Age_Group'].value_counts().reindex(age_fraud_rate.index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(age_fraud_rate.index, age_fraud_rate.values, \n",
    "               \n",
    "               alpha=0.8, edgecolor='black', width=0.7)\n",
    "\n",
    "# Add average line\n",
    "plt.axhline(y=global_avg_fraud_rate, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Global Average ({global_avg_fraud_rate:.2f}%)')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, fraud_rate) in enumerate(zip(bars, age_fraud_rate.values)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             f'{fraud_rate:.2f}%', ha='center', va='bottom', fontweight='bold',\n",
    "             bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Add transaction count labels below bars\n",
    "for i, (bar, count) in enumerate(zip(bars, age_group_counts.values)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, -max(age_fraud_rate.values)*0.05,\n",
    "             f'n={count}', ha='center', va='top', fontsize=9, fontstyle='italic',\n",
    "             bbox=dict(boxstyle='round,pad=0.2', facecolor='lightgray', alpha=0.7))\n",
    "\n",
    "plt.title(' Fraud Rate by Customer Age Group', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Fraud Rate (%)', fontweight='bold')\n",
    "plt.xlabel('Age Group', fontweight='bold')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adjust y-axis to accommodate both bar values and count labels\n",
    "plt.ylim(-max(age_fraud_rate.values)*0.1, max(age_fraud_rate.values)*1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"=\"*50)\n",
    "print(\"üìà AGE GROUP FRAUD ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Global Average Fraud Rate: {global_avg_fraud_rate:.2f}%\")\n",
    "print(\"\\nAge Group Breakdown:\")\n",
    "print(\"-\" * 40)\n",
    "for age_group, fraud_rate, count in zip(age_fraud_rate.index, age_fraud_rate.values, age_group_counts.values):\n",
    "    deviation = fraud_rate - global_avg_fraud_rate\n",
    "    deviation_pct = (deviation / global_avg_fraud_rate) * 100 if global_avg_fraud_rate > 0 else 0\n",
    "    print(f\"{age_group}: {fraud_rate:.2f}% ({count} transactions) | \"\n",
    "          f\"{'‚Üë' if deviation > 0 else '‚Üì'} {abs(deviation):.2f}% ({abs(deviation_pct):.1f}% {'above' if deviation > 0 else 'below'} avg)\")\n",
    "\n",
    "# Find highest and lowest risk age groups\n",
    "highest_risk = age_fraud_rate.idxmax()\n",
    "lowest_risk = age_fraud_rate.idxmin()\n",
    "print(f\"\\nüîç Highest Risk: {highest_risk} ({age_fraud_rate[highest_risk]:.2f}%)\")\n",
    "print(f\"üîç Lowest Risk: {lowest_risk} ({age_fraud_rate[lowest_risk]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5e02eae-c8fd-4645-a8d9-a2d28a597fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üë∂ Age-Based Fraud Insights  \n",
    "\n",
    "There is a noticeable trend where **younger customers (18-25) experience a significantly higher fraud rate üö®**.  \n",
    "\n",
    "### Possible Reasons:\n",
    "- **Higher digital engagement üì±** and exposure to phishing scams on social media.  \n",
    "- **Less awareness of security best practices üõ°Ô∏è**.  \n",
    "- **Potentially weaker passwords üîë**.  \n",
    "\n",
    "### üí° Actionable Insight:\n",
    "This finding can inform **targeted customer education campaigns üéì** aimed at younger demographics to reduce their risk of fraud.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5c75d9d-5466-4803-8511-ac4f79a9e565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ü§ñ ML Development ‚Äì Building the Fraud Detection Model  \n",
    "\n",
    "This section focuses on **developing machine learning models** to detect fraudulent transactions.  \n",
    "It covers:  \n",
    "\n",
    "- **Data Preprocessing üßπ** ‚Äì Cleaning, feature selection, encoding categorical variables.  \n",
    "- **Feature Engineering ‚öôÔ∏è** ‚Äì Creating meaningful variables from raw transaction data.  \n",
    "- **Model Selection üèÜ** ‚Äì Comparing algorithms like Logistic Regression, Random Forest, XGBoost, etc.  \n",
    "- **Training & Evaluation üìä** ‚Äì Splitting data, fitting models, and measuring performance.  \n",
    "- **Hyperparameter Tuning üîß** ‚Äì Optimizing model parameters for better accuracy.  \n",
    "- **Deployment Considerations üöÄ** ‚Äì Preparing the model for real-time fraud detection.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b81baef0-4f27-4f66-8bef-3cf71cf4e440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create an isolated copy for data preparation and modeling\n",
    "Model = df.copy()\n",
    "\n",
    "# 2. Inspect the new copy\n",
    "print('\\nView First Few Rows of the Model Dataset')\n",
    "display(Model.head(2))\n",
    "\n",
    "print('\\nBasic Dataset Info:')\n",
    "print(Model.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a271b5-35a4-4b33-a539-54322309bcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DATA CLEANING & PRE-PROCESSING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "729bcea5-69e5-43ec-8cf1-b6c3085cacbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üßπ Feature Selection ‚Äì Removing Unnecessary Columns  \n",
    "\n",
    "To improve model performance and reduce noise, the following **non-predictive columns** were removed:  \n",
    "\n",
    "- `Customer_ID`  \n",
    "- `Transaction_ID`  \n",
    "- `Customer_Name`  \n",
    "- `Customer_Contact`  \n",
    "- `Customer_Email`  \n",
    "- `Transaction_Description`  \n",
    "- `Age_Group`  \n",
    "- `Merchant_ID`  \n",
    "\n",
    "These fields are either **identifiers, personal details, or redundant features** that do not directly contribute to fraud prediction.  \n",
    "\n",
    "‚û°Ô∏è This helps ensure the model focuses only on **relevant behavioral and transactional features**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "475e2c42-566b-4eeb-be9d-847addbdc46d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "# Note: The columns to drop are based on the context provided and may need adjustment based on the actual dataset structure.\n",
    "# Ensure these columns are not needed for modeling.\n",
    "\n",
    "Model.drop(columns=['Customer_ID','Transaction_ID','Customer_Name','Customer_Contact','Transaction_Description','Customer_Email','Merchant_ID','Age_Group'], inplace=True, axis=1)\n",
    "print('\\n Columns dropped successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cab36611-85ad-4a52-a05b-eb979d04995d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Model.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ef39563-4ce1-4668-9369-8d0dc8105fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîß Feature Encoding Strategy  \n",
    "\n",
    "To prepare the dataset for machine learning, we applied **different encoding techniques** based on the type and cardinality of each categorical feature:\n",
    "\n",
    "### 1Ô∏è‚É£ One-Hot Encoding (Few Categories)\n",
    "- **Columns:** `Gender`  \n",
    "- Converts categorical values into **binary columns** (0/1) for each category.  \n",
    "- Ideal for columns with **low cardinality** to avoid dimensionality explosion.\n",
    "\n",
    "### 2Ô∏è‚É£ Frequency Encoding (High Cardinality)\n",
    "- **Columns:** `State`, `City`, `Transaction_Device`, `Transaction_Location` ,`Bank_Branch `\n",
    "- Each category is replaced with its **frequency (proportion) in the dataset**.  \n",
    "- Efficient for columns with **many unique values** to prevent too many new features.\n",
    "\n",
    "### 3Ô∏è‚É£ Label Encoding (Ordinal or Medium Cardinality)\n",
    "- **Columns:** `Account_Type`, `Transaction_Type`, `Merchant_Category`, `Device_Type`, `Transaction_Currency`, `Time_Bucket`  \n",
    "- Assigns **integer labels** to each category.  \n",
    "- Preserves **order information** if applicable and reduces dimensionality.\n",
    "\n",
    "üí° **Insight:**  \n",
    "Choosing the **right encoding strategy** ensures that the model can interpret categorical features **effectively** while keeping the dataset **manageable in size**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bc111ee-d8e8-4924-90eb-604355a1bf4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## üîß Feature Encoding Strategy  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\" Starting Feature Encoding Process...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store original shape for reference\n",
    "original_shape = Model.shape\n",
    "print(f\"Original dataset shape: {original_shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ One-Hot Encoding (Few Categories)\n",
    "# -----------------------------\n",
    "print(\"\\n One-Hot Encoding (Low Cardinality Features)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "one_hot_cols = ['Gender']\n",
    "for col in one_hot_cols:\n",
    "    if col in Model.columns:\n",
    "        print(f\"   Encoding: {col} (Unique values: {Model[col].nunique()})\")\n",
    "        Model = pd.get_dummies(Model, columns=[col], prefix=col, drop_first=False)\n",
    "    else:\n",
    "        print(f\"    Warning: Column '{col}' not found in dataset\")\n",
    "\n",
    "print(f\"   After one-hot encoding: {Model.shape[1]} columns\")\n",
    "\n",
    "# -----------------------------\n",
    "#  Frequency Encoding (High Cardinality)\n",
    "# -----------------------------\n",
    "print(\"\\n Frequency Encoding (High Cardinality Features)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "freq_cols = ['State', 'City', 'Transaction_Device', 'Transaction_Location','Bank_Branch']\n",
    "for col in freq_cols:\n",
    "    if col in Model.columns:\n",
    "        unique_count = Model[col].nunique()\n",
    "        print(f\"   Encoding: {col} (Unique values: {unique_count})\")\n",
    "        \n",
    "        # Calculate frequency (proportion)\n",
    "        freq_encoding = Model[col].value_counts(normalize=True)\n",
    "        \n",
    "        # Handle unseen values by assigning a low frequency (smoothing)\n",
    "        default_freq = 0.0001  # Small value for unseen categories\n",
    "        \n",
    "        # Apply frequency encoding\n",
    "        Model[col] = Model[col].map(freq_encoding).fillna(default_freq)\n",
    "        \n",
    "        print(f\"     Frequency range: {Model[col].min():.6f} - {Model[col].max():.6f}\")\n",
    "    else:\n",
    "        print(f\"    Warning: Column '{col}' not found in dataset\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Label Encoding (Ordinal / Medium Cardinality)\n",
    "# -----------------------------\n",
    "print(\"\\n Label Encoding (Medium Cardinality Features)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "label_cols = ['Account_Type', 'Transaction_Type', 'Merchant_Category', \n",
    "              'Device_Type', 'Transaction_Currency', 'Time_Bucket']\n",
    "\n",
    "# Initialize label encoders for each column (to keep mapping consistent)\n",
    "label_encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    if col in Model.columns:\n",
    "        unique_count = Model[col].nunique()\n",
    "        print(f\"   Encoding: {col} (Unique values: {unique_count})\")\n",
    "        \n",
    "        # Initialize and fit label encoder\n",
    "        le = LabelEncoder()\n",
    "        Model[col] = le.fit_transform(Model[col].astype(str))\n",
    "        label_encoders[col] = le  # Store encoder for potential inverse transform\n",
    "        \n",
    "        print(f\"     Encoded range: {Model[col].min()} - {Model[col].max()}\")\n",
    "    else:\n",
    "        print(f\"    Warning: Column '{col}' not found in dataset\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final Dataset Overview\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" Encoding Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_shape = Model.shape\n",
    "print(f\"Final dataset shape: {final_shape}\")\n",
    "print(f\"Columns added: {final_shape[1] - original_shape[1]}\")\n",
    "print(f\"Rows processed: {final_shape[0]}\")\n",
    "\n",
    "# Show sample of encoded data\n",
    "print(\"\\n Sample of Encoded Data (first 3 rows):\")\n",
    "print(\"-\" * 50)\n",
    "display(Model.head(3))\n",
    "\n",
    "# Show data types after encoding\n",
    "print(\"\\n Data Types After Encoding:\")\n",
    "print(\"-\" * 30)\n",
    "print(Model.dtypes.value_counts())\n",
    "print(\"\\nDetailed dtypes:\")\n",
    "for col, dtype in Model.dtypes.items():\n",
    "    if 'float' in str(dtype) or 'int' in str(dtype):\n",
    "        print(f\"  {col}: {dtype}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n Missing Values Check:\")\n",
    "print(\"-\" * 25)\n",
    "missing_values = Model.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\" No missing values found!\")\n",
    "else:\n",
    "    print(\" Missing values detected:\")\n",
    "    for col, count in missing_values[missing_values > 0].items():\n",
    "        print(f\"  {col}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00fb8b81-79fe-4794-88b7-9b088ca06b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#convert boolean columns to integers\n",
    "bool_cols = ['Is_Weekend', 'Gender_Female', 'Gender_Male']\n",
    "\n",
    "for col in bool_cols:\n",
    "    Model[col] = Model[col].astype(int)\n",
    "# Drop the columns\n",
    "Model = Model.drop(['Transaction_Date', 'Transaction_Time','Transaction_DateTime'], axis=1)\n",
    "\n",
    "Model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4bc3c96-1540-44bf-90a3-4b0c3dbef7cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = Model.drop(columns=['Is_Fraud'], axis=1)\n",
    "y = Model['Is_Fraud']\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=50, stratify=y  # stratify preserves class distribution\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with class_weight to handle imbalance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7e58f55-af0a-42d6-9640-2e930610a8f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dataset split information for classification\n",
    "print(\"=\"*50)\n",
    "print(\"CLASSIFICATION DATA SPLIT INFORMATION\".center(50))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Basic split information\n",
    "print(f\"\\n{'Data Split':<25}{'Samples':>15}{'Features':>15}\")\n",
    "print(f\"{'-'*25}{'-'*15}{'-'*15}\")\n",
    "print(f\"{'Training set (X_train)':<25}{X_train.shape[0]:>15}{X_train.shape[1]:>15}\")\n",
    "print(f\"{'Test set (X_test)':<25}{X_test.shape[0]:>15}{X_test.shape[1]:>15}\")\n",
    "print(f\"{'Target (y_train)':<25}{y_train.shape[0]:>15}{'':>15}\")\n",
    "print(f\"\\nPercentage split: {100*(1-0.2):.0f}% train / {100*0.2:.0f}% test\")\n",
    "print(f\"Random state: 50 (for reproducibility)\")\n",
    "\n",
    "# class distribution analysis\n",
    "if len(np.unique(y)) <= 10:  # Classification problem\n",
    "    print(\"\\n\" + \"=\"*25)\n",
    "    print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    # Get class labels (handles non-consecutive classes)\n",
    "    classes = np.unique(y)\n",
    "    train_counts = np.bincount(y_train, minlength=len(classes))\n",
    "    test_counts = np.bincount(y_test, minlength=len(classes))\n",
    "    \n",
    "    # Calculate ratios\n",
    "    train_ratios = train_counts / len(y_train)\n",
    "    test_ratios = test_counts / len(y_test)\n",
    "    \n",
    "    # Print detailed table\n",
    "    print(f\"\\n{'Class':<10}{'Train Count':>15}{'Train %':>12}{'Test Count':>15}{'Test %':>12}\")\n",
    "    print(f\"{'-'*10}{'-'*15}{'-'*12}{'-'*15}{'-'*12}\")\n",
    "    for i, (train_cnt, train_ratio, test_cnt, test_ratio) in enumerate(zip(train_counts, train_ratios, test_counts, test_ratios)):\n",
    "        print(f\"{i:<10}{train_cnt:>15}{train_ratio:>12.1%}{test_cnt:>15}{test_ratio:>12.1%}\")\n",
    "    \n",
    "    # Check for significant distribution differences\n",
    "    significant_diff = any(abs(train_ratios - test_ratios) > 0.05)  # 5% threshold\n",
    "    if significant_diff:\n",
    "        print(\"\\nWARNING: Significant difference in class distribution between train and test sets!\")\n",
    "        print(\"Consider using stratified sampling (stratify=y in train_test_split)\")\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    imbalance_threshold = 0.1  # Consider imbalance if minority class <10%\n",
    "    if any(train_ratios < imbalance_threshold):\n",
    "        print(\"\\nWARNING: Class imbalance detected!\")\n",
    "        print(\"Consider using:\")\n",
    "        print(\"- class_weight='balanced' in your model\")\n",
    "        print(\"- SMOTE oversampling\")\n",
    "        print(\"- Different evaluation metrics (precision/recall/F1 instead of accuracy)\")\n",
    "\n",
    "# Additional checks for classification\n",
    "print(\"\\n\" + \"=\"*25)\n",
    "print(\"MODELING RECOMMENDATIONS\")\n",
    "print(\"=\"*25)\n",
    "if len(np.unique(y)) == 2:\n",
    "    print(\"- Binary classification detected\")\n",
    "    print(\"- Recommended metrics: ROC-AUC, Precision, Recall, F1\")\n",
    "else:\n",
    "    print(f\"- Multiclass classification detected ({len(np.unique(y))} classes)\")\n",
    "    print(\"- Recommended metrics: F1-micro/macro, Confusion Matrix\")\n",
    "\n",
    "print(\"\\n- For logistic regression convergence issues:\")\n",
    "print(\"  1. Scale your data (StandardScaler)\")\n",
    "print(\"  2. Increase max_iter (default 100 is often too low)\")\n",
    "print(\"  3. Try different solvers (liblinear, saga, newton-cholesky)\")\n",
    "print(\"  4. Check for perfect separation warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57aa0f3c-ac9e-4dab-b3e2-6b40edd6e21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Build Pipeline for Scaling + Model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(\n",
    "        C=np.float64(10.0),  # Adjusted for better convergence\n",
    "        max_iter=5000,\n",
    "        class_weight='balanced',\n",
    "        solver='lbfgs',\n",
    "        multi_class='multinomial',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 4. Cross-validation (optional but good practice)\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\" Cross-validated Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# 5. Train final model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\" Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 8. ROC Curve (for each class if multi-class)\n",
    "if len(np.unique(y)) <= 5:  # Avoid clutter for too many classes\n",
    "    y_proba = pipeline.predict_proba(X_test)\n",
    "    for i in range(len(np.unique(y))):\n",
    "        fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(\" ROC Curve per Class\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1333a94-f392-460e-a441-c1e62b77293e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Build Pipeline with best params from GridSearchCV\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # optional for RF but kept for consistency\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        max_features=0.3,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# 4. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\" Cross-validated Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# 5. Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\" Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 8. ROC Curve (if few classes)\n",
    "if len(np.unique(y)) <= 5:\n",
    "    y_proba = pipeline.predict_proba(X_test)\n",
    "    for i in range(len(np.unique(y))):\n",
    "        fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(\" ROC Curve per Class\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 9. Check Overfitting\n",
    "train_acc = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "gap = train_acc - test_acc\n",
    "\n",
    "print(f\" Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\" Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\" Train-Test Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.05:\n",
    "    print(\" Potential Overfitting Detected\")\n",
    "else:\n",
    "    print(\" No major signs of overfitting\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba074637-fcaf-4f8a-a4a2-e8c805ae1dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Build Pipeline with XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Optional but can help\n",
    "    ('xgb', XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=len(y_resampled[y_resampled==0])/len(y_resampled[y_resampled==1]),  # Handle imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\" Cross-validated Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# 5. Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\" Confusion Matrix - XGBoost\")\n",
    "plt.show()\n",
    "\n",
    "# 8. ROC Curve (if few classes)\n",
    "if len(np.unique(y)) <= 5:\n",
    "    y_proba = pipeline.predict_proba(X_test)\n",
    "    for i in range(len(np.unique(y))):\n",
    "        fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(\" ROC Curve per Class - XGBoost\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 9. Check Overfitting\n",
    "train_acc = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "gap = train_acc - test_acc\n",
    "\n",
    "print(f\" Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\" Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\" Train-Test Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.05:\n",
    "    print(\" Potential Overfitting Detected\")\n",
    "else:\n",
    "    print(\" No major signs of overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbbe8f19-40e9-4d52-8c47-75366cb71406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Build Pipeline with LightGBM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Optional but can help\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        class_weight='balanced',  # Handles imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1  # Suppress output\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\" Cross-validated Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# 5. Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\" Confusion Matrix - LightGBM\")\n",
    "plt.show()\n",
    "\n",
    "# 8. ROC Curve (if few classes)\n",
    "if len(np.unique(y)) <= 5:\n",
    "    y_proba = pipeline.predict_proba(X_test)\n",
    "    for i in range(len(np.unique(y))):\n",
    "        fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(\" ROC Curve per Class - LightGBM\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 9. Feature Importance (LightGBM specific)\n",
    "feature_importances = pipeline.named_steps['lgbm'].feature_importances_\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else range(X_train.shape[1])\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])\n",
    "plt.title(' Top 15 Feature Importances - LightGBM')\n",
    "plt.xlabel('Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. Check Overfitting\n",
    "train_acc = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "gap = train_acc - test_acc\n",
    "\n",
    "print(f\" Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\" Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\" Train-Test Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.05:\n",
    "    print(\" Potential Overfitting Detected\")\n",
    "else:\n",
    "    print(\" No major signs of overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6382a928-2ef2-4b29-aae4-fee4ca263776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Define individual models\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    max_features=0.3,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=len(y_resampled[y_resampled==0])/len(y_resampled[y_resampled==1]) if len(np.unique(y)) == 2 else 1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# 4. Create ensemble model using Voting Classifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5. List of all models to compare\n",
    "models_to_compare = {\n",
    "    'Random Forest': rf_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LightGBM': lgbm_model,\n",
    "    'Ensemble': ensemble_model\n",
    "}\n",
    "\n",
    "# 6. Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models_to_compare.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "    \n",
    "    # Create pipeline for each model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = np.mean(cv_scores)\n",
    "    cv_std = np.std(cv_scores)\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    gap = train_acc - test_acc\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'gap': gap,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "\n",
    "# 7. Print Model Comparison Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" Model Comparison Summary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_model = None\n",
    "best_test_acc = 0\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  CV Accuracy = {result['cv_mean']:.4f} ¬± {result['cv_std']:.4f}\")\n",
    "    print(f\"  Train Accuracy = {result['train_acc']:.4f}\")\n",
    "    print(f\"  Test Accuracy = {result['test_acc']:.4f}\")\n",
    "    print(f\"  Train-Test Gap = {result['gap']:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if result['test_acc'] > best_test_acc:\n",
    "        best_test_acc = result['test_acc']\n",
    "        best_model = name\n",
    "\n",
    "print(f\" Best Model: {best_model} with test accuracy {best_test_acc:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 8. Detailed evaluation for the best model\n",
    "print(f\"\\n Detailed Classification Report for {best_model}:\")\n",
    "best_pipeline = results[best_model]['pipeline']\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# 9. Confusion Matrix for best model\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f\" Confusion Matrix - {best_model}\")\n",
    "plt.show()\n",
    "\n",
    "# 10. ROC Curve for best model (if binary classification)\n",
    "if len(np.unique(y)) == 2:\n",
    "    y_proba_best = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba_best)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f' ROC Curve - {best_model}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# 11. Additional comparison visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for plotting\n",
    "model_names = list(results.keys())\n",
    "test_accuracies = [results[name]['test_acc'] for name in model_names]\n",
    "train_accuracies = [results[name]['train_acc'] for name in model_names]\n",
    "cv_accuracies = [results[name]['cv_mean'] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x_pos - width, train_accuracies, width, label='Train Accuracy', alpha=0.8, color='skyblue')\n",
    "bars2 = ax.bar(x_pos, test_accuracies, width, label='Test Accuracy', alpha=0.8, color='lightgreen')\n",
    "bars3 = ax.bar(x_pos + width, cv_accuracies, width, label='CV Accuracy', alpha=0.8, color='lightcoral')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title(' Model Accuracy Comparison')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 12. Print gap analysis\n",
    "print(\"\\n Overfitting Analysis:\")\n",
    "for name, result in results.items():\n",
    "    status = \" Potential Overfitting\" if result['gap'] > 0.05 else \" No major overfitting\"\n",
    "    print(f\"{name}: Gap = {result['gap']:.4f} - {status}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a14783c-02d0-4a92-af5c-6ee40f6a4cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üèÅ Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22a57fbc-0130-42bc-b49f-220f22653545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Resample using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\" Resampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2,\n",
    "    random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 3. Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Define hyperparameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'lgbm__n_estimators': [100, 300],\n",
    "    'lgbm__max_depth': [5, 7],\n",
    "    'lgbm__learning_rate': [0.05, 0.1],\n",
    "    'lgbm__num_leaves': [31, 100],\n",
    "    'lgbm__subsample': [0.8],\n",
    "    'lgbm__colsample_bytree': [0.8],\n",
    "    'lgbm__min_child_samples': [20],\n",
    "    'lgbm__reg_alpha': [0, 0.1],\n",
    "    'lgbm__reg_lambda': [0, 0.1]\n",
    "}\n",
    "\n",
    "# 5. Perform GridSearchCV\n",
    "print(\" Performing GridSearchCV for hyperparameter tuning...\")\n",
    "print(f\" This may take some time. Testing {np.prod([len(v) for v in param_grid.values()])} parameter combinations...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# Fit GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\" GridSearch completed!\")\n",
    "print(f\" Best parameters: {grid_search.best_params_}\")\n",
    "print(f\" Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 6. Get the best model\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        **{k.replace('lgbm__', ''): v for k, v in grid_search.best_params_.items()},\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7. Train final model with best parameters\n",
    "print(\" Training Final LightGBM Model with best parameters...\")\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 8. Predict\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "y_proba = final_pipeline.predict_proba(X_test)\n",
    "\n",
    "# 9. Final Evaluation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FINAL MODEL EVALUATION - LightGBM (with GridSearch)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate metrics\n",
    "cv_scores = cross_val_score(final_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "train_acc = accuracy_score(y_train, final_pipeline.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "gap = train_acc - test_acc\n",
    "\n",
    "print(f\" Cross-validated Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "print(f\" Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\" Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\" Train-Test Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.05:\n",
    "    print(\"  Potential Overfitting Detected\")\n",
    "else:\n",
    "    print(\" No major signs of overfitting\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 10. Detailed Classification Report\n",
    "print(\"\\n Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 11. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\" Confusion Matrix - Final LightGBM Model (GridSearch Tuned)\")\n",
    "plt.show()\n",
    "\n",
    "# 12. ROC Curve (if binary classification)\n",
    "if len(np.unique(y)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(' ROC Curve - Final LightGBM Model (GridSearch Tuned)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# 13. Feature Importance\n",
    "feature_importances = final_pipeline.named_steps['lgbm'].feature_importances_\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])\n",
    "plt.title(' Top 15 Feature Importances - Final LightGBM Model (GridSearch Tuned)')\n",
    "plt.xlabel('Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 14. GridSearch Results Analysis\n",
    "print(\"\\n GridSearch Results Analysis:\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_results = results_df.nlargest(5, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(\" Top 5 Parameter Combinations:\")\n",
    "for i, (idx, row) in enumerate(top_results.iterrows(), 1):\n",
    "    print(f\"\\n{i}. Score: {row['mean_test_score']:.4f} ¬± {row['std_test_score']:.4f}\")\n",
    "    print(f\"   Parameters: {row['params']}\")\n",
    "\n",
    "# 15. Save the final model and results\n",
    "print(\"\\n Saving the final model and results...\")\n",
    "\n",
    "# Create model metadata\n",
    "model_metadata = {\n",
    "    'model_type': 'LightGBM',\n",
    "    'training_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'best_parameters': {k.replace('lgbm__', ''): v for k, v in grid_search.best_params_.items()},\n",
    "    'performance_metrics': {\n",
    "        'best_cv_score': float(grid_search.best_score_),\n",
    "        'cv_accuracy_mean': float(np.mean(cv_scores)),\n",
    "        'cv_accuracy_std': float(np.std(cv_scores)),\n",
    "        'train_accuracy': float(train_acc),\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'train_test_gap': float(gap)\n",
    "    },\n",
    "    'grid_search_info': {\n",
    "        'n_parameter_combinations': len(grid_search.cv_results_['params']),\n",
    "        'cv_folds': grid_search.cv,\n",
    "        'scoring_metric': grid_search.scoring\n",
    "    },\n",
    "    'feature_names': feature_names.tolist() if hasattr(feature_names, 'tolist') else feature_names\n",
    "}\n",
    "\n",
    "# Save the model pipeline\n",
    "joblib.dump(final_pipeline, 'final_lightgbm_model_gridsearch.pkl')\n",
    "print(\" Model pipeline saved as 'final_lightgbm_model_gridsearch.pkl'\")\n",
    "\n",
    "# Save model metadata\n",
    "with open('model_metadata_gridsearch.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "print(\" Model metadata saved as 'model_metadata_gridsearch.json'\")\n",
    "\n",
    "# Save feature importances\n",
    "importance_df.to_csv('feature_importances_gridsearch.csv', index=False)\n",
    "print(\" Feature importances saved as 'feature_importances_gridsearch.csv'\")\n",
    "\n",
    "# Save grid search results\n",
    "results_df.to_csv('gridsearch_results.csv', index=False)\n",
    "print(\" GridSearch results saved as 'gridsearch_results.csv'\")\n",
    "\n",
    "# 16. Final Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FINAL MODEL SUMMARY (with GridSearch)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: LightGBM Classifier\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Cross-Validation Score: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Training completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 17. Performance comparison with default parameters\n",
    "print(\"\\n Performance Comparison: Default vs Tuned Parameters\")\n",
    "\n",
    "# Train with default parameters for comparison\n",
    "default_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "default_pipeline.fit(X_train, y_train)\n",
    "default_test_acc = accuracy_score(y_test, default_pipeline.predict(X_test))\n",
    "\n",
    "print(f\" Default Parameters Test Accuracy: {default_test_acc:.4f}\")\n",
    "print(f\" Tuned Parameters Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\" Improvement: {(test_acc - default_test_acc):.4f} ({((test_acc - default_test_acc)/default_test_acc)*100:.2f}%)\")\n",
    "\n",
    "# 18. Example of how to load and use the model later\n",
    "print(\"\\n Example usage code for production:\")\n",
    "print(\"\"\"\n",
    "# Load the saved model\n",
    "import joblib\n",
    "loaded_model = joblib.load('final_lightgbm_model_gridsearch.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(new_data)\n",
    "probabilities = loaded_model.predict_proba(new_data)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313603a5-6d4d-4546-a091-bb66d8f8b255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fraud Detection System - Executive Summary\n",
    "\n",
    "## Performance Overview\n",
    "- **Final Model Accuracy:** 97.23%  \n",
    "- **Improvement over Default Model:** +0.27%  \n",
    "- **Global Fraud Rate:** 5.04% of all transactions  \n",
    "\n",
    "---\n",
    "\n",
    "## Key Business Insights\n",
    "\n",
    "### High-Risk Categories\n",
    "- **Clothing Retailers:** 5.20% fraud rate (highest risk)  \n",
    "- **Groceries & Restaurants:** ~5.19% fraud rate  \n",
    "- **Entertainment:** 4.82% fraud rate (lowest risk)  \n",
    "\n",
    "### Customer Risk Profile\n",
    "- **Young Adults (18-25):** 5.24% fraud rate (highest risk)  \n",
    "- **Seniors (66+):** 4.86% fraud rate (lowest risk)  \n",
    "- **Weekdays vs Weekends:** 5.69% vs 4.91% fraud rate  \n",
    "\n",
    "### Device Risk Analysis\n",
    "- **Dashboard Cards:** 5.59% fraud rate (most risky)  \n",
    "- **Virtual Cards:** 5.45% fraud rate  \n",
    "- **Mobile POS:** Lower risk profile  \n",
    "\n",
    "---\n",
    "\n",
    "## Immediate Actions Recommended\n",
    "- **Enhanced Monitoring** for clothing retailers and young customers  \n",
    "- **Focused Verification** during weekdays and high-risk time windows  \n",
    "- **Device-Based Security Tiers** for different risk levels  \n",
    "- **Age-Segmented Authentication Flows** for targeted checks  \n",
    "\n",
    "---\n",
    "\n",
    "## Future Roadmap\n",
    "\n",
    "### Phase 1 (3‚Äì6 months)\n",
    "- Implement **advanced models** (CatBoost, Neural Networks)  \n",
    "- Deploy **real-time scoring** for faster detection  \n",
    "\n",
    "### Phase 2 (6‚Äì12 months)\n",
    "- Integrate **behavioral biometrics** for stronger security  \n",
    "- Apply **network analysis** to uncover organized fraud  \n",
    "\n",
    "### Phase 3 (12‚Äì18 months)\n",
    "- Enable **online learning capabilities** for continuous model updates  \n",
    "- Incorporate **Explainable AI** for transparency and stakeholder trust  \n",
    "\n",
    "---\n",
    "\n",
    "## Business Impact\n",
    "- **Reduced Losses:** Targeted prevention in high-risk segments  \n",
    "- **Improved Customer Experience:** Streamlined flows for low-risk users  \n",
    "- **Scalable Solution:** Foundation for ongoing fraud detection improvements  \n",
    "- **Actionable Insights:** Clear patterns for immediate implementation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a551f987-7a05-4a36-a40e-28bee6442b50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Financial Fraud Modeling for LOL Bank",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
